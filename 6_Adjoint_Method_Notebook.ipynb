{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjoint Method\n",
    "\n",
    "In this notebook, we derive, implement, and verify the **adjoint method**, a technique for efficiently computing derivatives for our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate data:\n",
    "\n",
    "- The real data, using the real atmospheric forcing\n",
    "- Fake data, using our noisy atmospheric forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr,nc = 32,32\n",
    "dt = 0.01\n",
    "F = 0.1\n",
    "\n",
    "#C_control is the covariance matrix of the full control vector f\n",
    "\n",
    "C_control, x0, _, M = helper.generate_world(nr, nc, dt, F)\n",
    "\n",
    "#C_known is the covariance matrix of the correct part of the control vector f\n",
    "#C_error is the covariance matrix of the incorrect part of the control vector f\n",
    "\n",
    "gamma = 2/3\n",
    "\n",
    "C_known = C_control * gamma\n",
    "C_error = C_control * (1-gamma)\n",
    "C_ocean = C_control / 6\n",
    "\n",
    "f_true, f_guess = helper.generate_true_and_first_guess_field(C_known, C_error, nr, nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atmosphere forcing coefficient\n",
    "F = 0.1\n",
    "# Standard deviation of the noise in the observations\n",
    "sigma = 0.1 \n",
    "\n",
    "\n",
    "# Number of timesteps to run the simulation for (repeated each iter)\n",
    "num_timesteps = 10\n",
    "# Number of iterations of gradient descent (repeated each run)\n",
    "num_iters = 5\n",
    "# Step size for gradient descent\n",
    "step_size = 0.1\n",
    "\n",
    "# Number of times to run the whole gradient descent optimization\n",
    "num_runs = 1\n",
    "\n",
    "# Run the simulation with the true and guessed control vector\n",
    "saved_timesteps, real_state_over_time  = helper.compute_affine_time_evolution_simple(x0, M, F*f_true,  num_timesteps)\n",
    "saved_timesteps, guess_state_over_time = helper.compute_affine_time_evolution_simple(x0, M, F*f_guess, num_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we'll need observations of the real ocean state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_per_timestep = 50\n",
    "\n",
    "\n",
    "\n",
    "observed_state_over_time_2d = helper.observe_over_time(real_state_over_time, sigma, \n",
    "                                                       num_obs_per_timestep, nr, nc)\n",
    "\n",
    "\n",
    "observed_state_over_time =     [np.reshape(observed_state_2d, (nr*nc, 1)) \n",
    "                                for observed_state_2d in observed_state_over_time_2d]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "Our goal is to use our ocean simulation to improve our estimate of atmospheric conditions.\n",
    "\n",
    "Here's the basic outline:\n",
    "\n",
    "- We have a model of the ocean, that depends on atmospheric conditions.\n",
    "\n",
    "- We have an initial estimate for our atmospheric state. \n",
    "  - We use it to simulate our ocean model.\n",
    "\n",
    "- If our atmosphere estimate is inaccurate, it will likely cause some inaccuracies in our ocean simulation.\n",
    "  - We can compute our inaccuracy by observing the real ocean state, and comparing it to the simulation.\n",
    "  \n",
    "- We can use the derivative chain rule to determine how to improve the ocean model, by adjusting our atmospheric estimate.\n",
    "  - We use the adjoint method to create this chain rule more efficiently.\n",
    "\n",
    "Hopefully, this adjusted atmospheric estimate is better than our old one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress So Far\n",
    "\n",
    "\n",
    "We've already handled the first three parts:\n",
    "\n",
    "- We have an **ocean model**.\n",
    "- We've created a \"true\" atmosphere, and an **estimated** version of that atmosphere.\n",
    "- We have modelled the process of gathering **observations**.\n",
    "\n",
    "Now, we want to handle the last part: using those observations to improve our atmospheric estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss of our model\n",
    "\n",
    "First, we'll use our observations to evaluate the quality of our ocean simulation. We'll need some variables to write this clearly.\n",
    "\n",
    "First, important properties of our system:\n",
    "- $x^*(t)$ is the **true ocean state** (the temperature of the atmosphere in each region).\n",
    "- $f^*(t)$ is the **true atmospheric forcing** (temperature of the atmosphere) over time.\n",
    "- $z(t)$ is the **observed ocean state**: for the sake of this problem, we'll treat it as if it were the true ocean state.\n",
    "- $x(0)$ is the **initial ocean state**.\n",
    "  - We'll assume that this is perfectly accurate: we'll use this to initialize our simulation.\n",
    "  - We could, however, modify our problem to also improve this variable, as well.\n",
    "\n",
    "Next, variables that describe our estimates:\n",
    "- $x(t)$ is our estimate of the **ocean state**, based on our **simulation**.\n",
    "  - We run our simulation for $\\tau$ timesteps.\n",
    "- $f(t)$ is our **first guess estimate** of the **atmospheric control**. \n",
    "  - This is used when we're simulating $x(t)$.\n",
    "\n",
    "- $J$ is our **loss function**, representing how bad our estimate is (larger $J$, worse estimate).\n",
    "  - This loss function will compare $x(t)$ to $z(t)$.\n",
    "\n",
    "The simplest useful model for our loss is *squared difference*: the larger the squared difference between the **observed** and **simulated** ocean state, the less accurate our simulation is.\n",
    "\n",
    "In 1D, if we normalize by the variance, we get:\n",
    "\n",
    "$$J_{1D}(t) = (z(t) - x(t))^2 / \\sigma^2$$\n",
    "\n",
    "In the multivariable case (where $z(t)$ and $x(t)$ are vectors, and $W$ is the covariance of observation error), we get\n",
    "\n",
    "$$J_{2D}(t) = \\Big( z(t) - x(t) \\Big)^\\top W^{-1}\n",
    "              \\Big( z(t) - x(t) \\Big)$$\n",
    "\n",
    "Finally, we sum this up over all timesteps: we get our total squared difference.\n",
    "\n",
    "$$J = \\sum_{t=1}^{\\tau}\n",
    "      \\Big( z(t) - x(t) \\Big)^\\top W^{-1}\n",
    "      \\Big( z(t) - x(t) \\Big)$$\n",
    "\n",
    "Our goal is to *minimize* this function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deriving the Adjoint Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our goal: computing a derivative\n",
    "\n",
    "For convenience later, we choose an arbitrary timestep $q$. \n",
    "\n",
    "Our goal is to modify our atmospheric forcing $f(q)$ to improve our simulation (in other words, reducing $J$). This can be best represented by asking, \"how does modifying $f(q)$ affect $J$?\" This question is answered by the derivative,\n",
    "\n",
    "$$\\frac{ d J}{ d f(q)}$$\n",
    "\n",
    "We can use this to directly compute an adjustment to $f(q)$, to improve our estimate. So, this derivative is our goal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does $f(q)$ affect $J$? It doesn't directly show up in the equation for $J$.\n",
    "\n",
    "- Rather, it *indirectly* affects $J$, by modifying the (simulated) ocean state, $x(t)$.\n",
    "\n",
    "This effect is represented by our equation for simulating forward in time:\n",
    "\n",
    "$$x(t+1) = Mx(t) + Ff(t)$$\n",
    "\n",
    "$f(q)$ influences the next state $x(q+1)$, which contributes to $J$. But, we're forgetting a second way that $f(q)$ can affect $J$: by affecting *future states*.\n",
    "\n",
    "- While $f(q)$ only directly affects $x(q+1)$, we use $x(q+1)$ to compute $x(q+2)$. We can then use $x(q+2)$ to compute $x(q+3)$, and so on.\n",
    "- So, $f(q)$ affects all of our future states! \n",
    "- By affecting each of these states, $f(q)$ can affect $J$ at $\\tau - q  $ different states.\n",
    "\n",
    "We can account for all of these terms using the multivariable chain rule:\n",
    "\n",
    "$$\\frac{ d J}{ d f(q)} \\quad {\\LARGE=}\\quad  \\sum_{t = q+1}^{\\tau} \\frac{dx(q+1)}{df(q)} \\cdot \\frac{dx(t)}{dx(q+1)}  \\cdot \\frac{\\partial J}{ \\partial x(t)} $$\n",
    "\n",
    "We know how to compute each of these terms: the first and third terms are known matrix derivatives, so we'll put them off until later.\n",
    "\n",
    "It's useful to think of this in a second way: above, we've listed every way that $x(q+1)$ can affect $J$. We have a *total derivative* of $J$ with respect to $x(q+1)$.\n",
    "\n",
    "$$\\frac{ d J}{ d f(q)} \\quad {\\LARGE=}\\quad  \\frac{dx(q+1)}{df(q)} \n",
    "\\Bigg( \\sum_{t = q+1}^{\\tau} \\frac{dx(t)}{dx(q+1)}  \\cdot \\frac{\\partial J}{ \\partial x(t)} \\Bigg) \n",
    "\\quad {\\LARGE=}\\quad \n",
    "\\frac{dx(q+1)}{df(q)} \\Bigg( \\frac{dJ}{dx(q+1)} \\Bigg)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundant calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique gets the job done, but it can be inefficient to use for multiple timesteps: we have a lot of duplicate calculations. Consider an example:\n",
    "\n",
    "- $f(1)$ and $f(2)$ both affect $x(3)$, which in turn affects $J$. Thus, both equations require $\\frac{dJ}{dx(3)}$.\n",
    "\n",
    "$$\\frac{ d J}{ d f(1)} \n",
    "\\quad{\\LARGE=}\\quad  \n",
    "\\frac{dx(2)}{df(1)} \\Bigg(  \\overbrace{\\frac{dJ}{dx(2)}}^{\\text{Total effect of $x(2)$}}\\Bigg) \n",
    "\\quad{\\LARGE=}\\quad \n",
    "\\frac{dx(2)}{df(1)} \\Bigg( \n",
    "    \\overbrace{\n",
    "        \\frac{\\partial J}{ \\partial x(2)}\n",
    "     }^{\\text{ $x(2)$ effect by itself}}\n",
    "+ \n",
    "\\overbrace{\n",
    "\\frac{dx(3)}{dx(2)} \\textcolor{red}{\\frac{dJ}{dx(3)}}\n",
    "}^{\\text{$x(2)$ effect via future timesteps}} \\Bigg) \n",
    "$$\n",
    "\n",
    "$$\\frac{ d J}{ d f(2)} \n",
    "\\quad{\\LARGE=}\\quad  \n",
    "\\frac{dx(3)}{df(1)} \\Bigg(  \\red{\\frac{dJ}{dx(3)}}\\Bigg) \n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Adjoint Method: Base Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that, in the above case, it would make sense to compute $dJ/dx(3)$ first, so we can re-use it for computing $dJ/dx(2)$.\n",
    "\n",
    "- But if we just showed that $dJ/dx(3)$ is used for twice, doesn't it make sense that the same is true for $dJ/dx(4)$?\n",
    "  - If we use an identical argument to before, we could show that computing $dJ/dx(3)$ involves computing $dJ/dx(4)$.\n",
    "  - So, we should handle $dJ/dx(4)$ first.\n",
    "\n",
    "We can use the same logic over and over, going further forward in time: it seems we're reusing a lot of calculations! \n",
    "\n",
    "The natural conclusion is for us to start with the very last timestep, $dJ/dx(\\tau)$.\n",
    "\n",
    "- Because there are no future timesteps, $x(\\tau)$ can only affect $J$ directly:\n",
    "\n",
    "$$\\frac{d J}{d x(\\tau)} = \\frac{\\partial J}{ \\partial x(\\tau)}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Adjoint Method: Recursion\n",
    "\n",
    "Now, we can move one step **backwards** in time, using the equation we wrote above:\n",
    "\n",
    "$$ \\textcolor{red}{\\frac{d J}{d x(\\tau-1)}} \n",
    "\\quad{\\LARGE=}\\quad\n",
    "\\overbrace{\\frac{\\partial J}{ \\partial x(\\tau-1)}}^{\\text{ $x(\\tau-1)$ effect by itself}} + \n",
    "\\overbrace{\\frac{dx(\\tau) }{dx(\\tau-1)}\\textcolor{red}{\\frac{d J}{d x(\\tau)}}}^{\\text{$x(\\tau-1)$ effect via $x(\\tau)$}}$$\n",
    "\n",
    "To make things clearer, we'll rename the variable we're recursively building up:\n",
    "\n",
    "$$ \\lambda_t = \\frac{d J}{d x(t)} $$\n",
    "\n",
    "Rewriting our equation:\n",
    "\n",
    "$$ \\textcolor{red}{\\lambda_{\\tau-1}} = \\frac{\\partial J}{ \\partial x(\\tau-1)} + \\frac{dx(\\tau) }{dx(\\tau-1)} \\textcolor{red}{\\lambda_{\\tau}}$$\n",
    "\n",
    "We get something that looks like a **recursive** relation: $\\lambda_{\\tau-1}$ references the next element in the sequence, $\\lambda_{\\tau}$. As we move further back in time, we find the exact same equation, confirming our suspicions. If we write it in general, we get:\n",
    "\n",
    "$$ \\lambda_{t} = \n",
    "\\begin{cases}\n",
    "\\frac{\\partial J}{ \\partial x(t)} + \\frac{dx(t+1) }{dx(t)} \\lambda_{t+1} & \\text{ if } t < \\tau \\\\\\\\\n",
    "\\frac{\\partial J}{ \\partial x(t)} & t = \\tau\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "These are our **adjoint variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the adjoint\n",
    "\n",
    "We can find our adjoint variables by moving backwards in time: we start by computing $\\lambda_{\\tau}$, and begin decrementing through $t = \\tau-1, \\tau-2,..., 2,1$.\n",
    "\n",
    "Once we've finished, it's easy to compute our final derivatives:\n",
    "\n",
    "$$\n",
    "\\frac{ d J}{ d f(q)} \\quad {\\LARGE=}\\quad  \\frac{dx(q+1)}{df(q)} \\lambda_{q+1}  \n",
    "$$\n",
    "\n",
    "If we apply this to our model ($x(t+1) = Mx(t) + Ff(t)$), we find that $ \\frac{dx(t+1) }{dx(t)} = M^\\top $ \n",
    "\n",
    "$$ \\lambda_{t} = \n",
    "\\begin{cases}\n",
    "\\frac{\\partial J}{ \\partial x(t)} + M^\\top \\lambda_{t+1} & \\text{ if } t < \\tau \\\\\\\\\n",
    "\\frac{\\partial J}{ \\partial x(t)} & t = \\tau\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "If we work through the induction, we can simplify this to:\n",
    "\n",
    "$$ \\lambda_{k} = \\sum_{i=k}^\\tau \\Bigg( (M^{i-k})^\\top \\frac{\\partial J}{ \\partial x(i)} \\Bigg)\n",
    "$$\n",
    "\n",
    "And finally:\n",
    "\n",
    "$$\n",
    "\\frac{ d J}{ d f(q)}\n",
    "\\quad {\\LARGE=}\\quad\n",
    "F \\lambda_{q+1} \n",
    "\\quad {\\LARGE=}\\quad\n",
    "F \\sum_{i=q+1}^\\tau \\Bigg( (M^{i-q-1})^\\top \\frac{\\partial J}{ \\partial x(i)} \\Bigg)\n",
    "$$\n",
    "\n",
    "Notice that the last forcing, $f(\\tau)$, actually has no effect on our loss: it would be applied to a future state $x(\\tau+1)$, that doesn't exist.\n",
    "\n",
    "- In the above equation, this would refer to some non-existent $\\lambda_{\\tau+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is the adjoint useful?\n",
    "\n",
    "Something worth addressing:\n",
    "\n",
    "**Q:** *Couldn't we have computed the answer in our original form, without invoking the adjoint? We could've just plugged values into the chain rule we started with.*\n",
    "\n",
    "In this particular case, this is true. However, this is only simple, because our model takes on such a simple form, where we can multiply by $A^T$ repeatedly to get our answer.\n",
    "\n",
    "In many situations, our model can be too complex to get an analytical derivative. So, instead, we might use a more demanding approach, like **finite difference approximation**:\n",
    "\n",
    "- Modify one variable of $f(q)$ and simulate the whole model, seeing how the loss changes.\n",
    "\n",
    "- We repeat this process for each variable in $f(q)$, to get the overall derivative.\n",
    "\n",
    "- Then, we have to repeat *all* of that, for every timestep $q$.\n",
    "\n",
    "Using the adjoint method, we can significantly cut down on the work we have to do:\n",
    "\n",
    "- First, we compute the adjoint variables $\\lambda_t$: this requires computing our derivatives $\\partial J/\\partial x(t)$ and $\\partial x(t+1)/\\partial x(t)$. \n",
    "\n",
    "  - $\\partial J/\\partial x(t)$ can be gotten directly from the loss function.\n",
    "  - $\\partial x(t+1)/x(t)$ only requires simulating one timestep forward, for each variable.\n",
    "\n",
    "Since we have to simulate between each pair of timesteps $t$ and $t+1$, this is equivalent to running through the whole model once (per variable in $x$).\n",
    "\n",
    "Once we've done that, we don't need to run the whole simulation for each $f(q)$: we only have to run one timestep, to see how it affects $x(q+1)$.\n",
    "\n",
    "We can think of this as \"pre-simulating\" the effect that our states have on the loss, so that we only have to see how $f(q)$ affects the first in that chain of timesteps: $x(q+1)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Adjoint Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the adjoint method (for our particular case), let's implement it.\n",
    "\n",
    "A few more details:\n",
    "\n",
    "- Our $f$ is time-invariant: we're using the same $f(q)$ for all timesteps.\n",
    "- This isn't too much of a problem: we can just add up the derivative contributions over all timesteps.\n",
    "\n",
    "$$\n",
    "\\frac{ d J}{ d f}\n",
    "\\quad {\\LARGE=}\\quad\n",
    "\\sum_{q=1}^{\\tau-1}\n",
    "F \\lambda_{q+1} \n",
    "$$\n",
    "\n",
    "And one last thing:\n",
    "\n",
    "- We only observe some pixels: so, we simply ignore the remaining pixels. We leave them as NaNs, and are careful to exclude them from our calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Loss\n",
    "\n",
    "Let's start by defining the loss we're going to be computing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Jt(xt_true, xt_guess): \n",
    "    \"\"\"\n",
    "    Computes squared loss between two vectors at time t.\n",
    "    \n",
    "    Args:\n",
    "    xt_true (np.ndarray): True state vector at time t\n",
    "    xt_guess (np.ndarray): Guessed state vector at time t\n",
    "    \n",
    "    Returns:\n",
    "    float: Squared loss, or 0 if no valid terms\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sum over all valid terms, using numpy to treat nans as zeros\n",
    "    result = np.nansum((xt_true - xt_guess)**2)\n",
    "    if np.isnan(result): \n",
    "        return 0\n",
    "    else: \n",
    "        return result\n",
    "\n",
    "def compute_J(x_true, x_guess): \n",
    "    \"\"\"\n",
    "    Computes total squared loss between two vectors across all timesteps.\n",
    "    \n",
    "    Args:\n",
    "    x_true (list): List of true state vectors at each timestep\n",
    "    x_guess (list): List of guessed state vectors at each timestep\n",
    "    \n",
    "    Returns:\n",
    "    float: Total squared loss across all timesteps\n",
    "    \"\"\"\n",
    "    return np.sum([\n",
    "                compute_Jt(x_true[i], x_guess[i]) for i in range(len(x_true))]\n",
    "                )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Derivatives\n",
    "\n",
    "Now, we can begin computing the derivatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DJ_Dxt(xt_true, xt_guess):\n",
    "    \"\"\"\n",
    "    Computes partial derivative of squared loss w.r.t. guessed state at time t.\n",
    "    \n",
    "    Args:\n",
    "    xt_true (np.ndarray): True state vector at time t\n",
    "    xt_guess (np.ndarray): Guessed state vector at time t\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Partial derivative of loss, with NaNs treated as 0\n",
    "    \"\"\"\n",
    "    return np.nan_to_num( 2*(xt_guess - xt_true), nan = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the percent error, our analytical (using chain rule) and empirical (taking finite difference) calculations of $\\frac{dJ}{dx(t)}$ values are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Adjoint\n",
    "\n",
    "Using these derivatives, you can build up the adjoint, as described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_adjoints(DJ_Dx, dxtp1_dxt):\n",
    "    \"\"\"\n",
    "    Computes adjoint variables for optimization using backwards-time recursion.\n",
    "\n",
    "    Args:\n",
    "    DJ_Dx (list): List of partial derivatives of loss w.r.t. state at each timestep\n",
    "    dxtp1_dxt (list): List of total derivatives of next state w.r.t. current state at each timestep\n",
    "\n",
    "    Returns:\n",
    "    list: Adjoint variables for each timestep, in forward time order\n",
    "    \"\"\"\n",
    "\n",
    "    tau = len(DJ_Dx)\n",
    "    adjoints = [0] * tau # Initialize list of adjoints\n",
    "\n",
    "    adjoints[tau-1] = DJ_Dx[tau-1]\n",
    "    \n",
    "    for t in range(tau-2, -1, -1):  # Backwards in time\n",
    "        adjoint = DJ_Dx[t] + dxtp1_dxt[t] @ adjoints[t+1]\n",
    "\n",
    "        adjoints[t] = adjoint\n",
    "\n",
    "    return adjoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to use the adjoint to compute $\\frac{dJ}{df}$. So, let's try that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dJ_df(M, F, observed_state_over_time, simulated_state_over_time):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the loss with respect to the forcing field f for the linear model:\n",
    "    x(t+1) = Mx(t) + Ff\n",
    "\n",
    "    Args:\n",
    "    M (np.ndarray): Model matrix\n",
    "    F (float): Forcing coefficient\n",
    "    observed_state_over_time (list): List of observed states at each timestep\n",
    "    simulated_state_over_time (list): List of simulated states at each timestep\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Gradient of the loss with respect to the forcing field f\n",
    "    \"\"\"\n",
    "    num_timesteps = len(observed_state_over_time)\n",
    "    vec_length = len(observed_state_over_time[0])\n",
    "\n",
    "    #Compute adjoints\n",
    "    DJ_Dx = [compute_DJ_Dxt(observed_state_over_time[i], simulated_state_over_time[i])\n",
    "             for i in range(num_timesteps)] # partial J / partial x(t)\n",
    "    \n",
    "    dxtp1_dxt = [M.T for i in range(num_timesteps-1)] #dx(t+1)/dx(t)\n",
    "\n",
    "    adjoints = compute_adjoints(DJ_Dx, dxtp1_dxt) # dJ/dx(t) = lambda(t)\n",
    "\n",
    "    # Compute gradient for each timestep: how f being applied at time t affects J\n",
    "    dJ_dft = [ F * adjoint for adjoint in adjoints[1:] ] # dJ/df(t) = dx(t+1)/df(t) dJ/dx(t+1)\n",
    "    dJ_dft.append(np.zeros((vec_length,1))) # dJ/df(tau) = 0 \n",
    "\n",
    "    #f is applied the same at all timesteps\n",
    "    dJ_df = np.sum(dJ_dft, axis=0) # dJ/df = sum_t dJ/df(t)\n",
    "    return dJ_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the adjoint, we now have a complete pipeline for computing $dJ/df$. In the next notebook, we'll use this in our gradient descent implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying our Adjoint Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is difficult to visualize, to ensure that it's (approximately) correct.\n",
    "\n",
    "- Our solution is to **numerically** compute the derivatives, and compare them to what we find above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to evaluate the functionality of ```compute_DJ_Dxt```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent error at timestep 0: 0.00000001%\n",
      "Percent error at timestep 1: 0.00000002%\n",
      "Percent error at timestep 2: 0.00000002%\n",
      "Percent error at timestep 3: 0.00000002%\n"
     ]
    }
   ],
   "source": [
    "def test_DJ_Dxt(observed_state_over_time, simulated_state_over_time, num_timesteps, epsilon = 1e-6):\n",
    "    \"\"\"\n",
    "    This function tests ( partial J /partial xt ) by comparing it to a finite-difference approximation.\n",
    "    It checks the gradient of J with respect to x(t) for each timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    percent_errors = []\n",
    "    vec_length = len(observed_state_over_time[0])\n",
    "\n",
    "    ### Compute analytic gradient using expression for loss\n",
    "    DJ_Dx = [compute_DJ_Dxt(observed_state_over_time[t], simulated_state_over_time[t])\n",
    "                 for t in range(num_timesteps)]\n",
    "\n",
    "    ### Compute numerical gradient using finite differences\n",
    "    for t in range(num_timesteps):\n",
    "        DJ_Dxt_approx = np.zeros((vec_length, 1))\n",
    "\n",
    "        for i in range(vec_length):\n",
    "            # Perturb x(t) in each dimension\n",
    "            state_t_plus = simulated_state_over_time[t].copy()\n",
    "            state_t_minus = simulated_state_over_time[t].copy()\n",
    "\n",
    "            state_t_plus[i] += epsilon\n",
    "            state_t_minus[i] -= epsilon\n",
    "\n",
    "            # Compute how perturbation affects J\n",
    "            J_plus  = compute_Jt(observed_state_over_time[t], state_t_plus)\n",
    "            J_minus = compute_Jt(observed_state_over_time[t], state_t_minus)\n",
    "\n",
    "            # Compute finite difference approximation\n",
    "            DJ_Dxt_approx[i] = (J_plus - J_minus) / (2*epsilon)\n",
    "\n",
    "        DJ_Dxt = DJ_Dx[t]\n",
    "\n",
    "        # Compute percent error between analytic (loss fn) and numerical (finite-difference) gradients\n",
    "        percent_error = 100*np.linalg.norm(DJ_Dxt - DJ_Dxt_approx) / np.linalg.norm(DJ_Dxt)\n",
    "        percent_errors.append(percent_error)\n",
    "\n",
    "    return percent_errors\n",
    "\n",
    "num_timesteps = 4\n",
    "# Call the function with all necessary arguments\n",
    "percent_errors = test_DJ_Dxt(observed_state_over_time, guess_state_over_time, num_timesteps)\n",
    "\n",
    "# Print results\n",
    "\n",
    "for t, percent_error in enumerate(percent_errors):\n",
    "    print(f\"Percent error at timestep {t}: {percent_error:.8f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to evaluate the functionality of ```compute_adjoints```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent error at timestep 0: 0.00000028%\n",
      "Percent error at timestep 1: 0.00000020%\n",
      "Percent error at timestep 2: 0.00000009%\n",
      "Percent error at timestep 3: 0.00000002%\n"
     ]
    }
   ],
   "source": [
    "def test_adjoint(observed_state_over_time, x0, M, F, f_guess, num_timesteps, nr, nc, epsilon = 1e-6):\n",
    "    \"\"\"\n",
    "    This function tests compute_adjoints by comparing it to a numerical approximation of the adjoints.\n",
    "    Note that the adjoints are dJ/dx(t) = lambda(t).\n",
    "    \"\"\"\n",
    "    percent_errors = []\n",
    "\n",
    "    vec_length = len(observed_state_over_time[0])\n",
    "\n",
    "    _, simulated_state_over_time = helper.compute_affine_time_evolution_simple(x0, M, F*f_guess, num_timesteps)\n",
    "\n",
    "    ### Compute analytical gradient using adjoint method\n",
    "    DJ_Dx = [compute_DJ_Dxt(observed_state_over_time[i], simulated_state_over_time[i])\n",
    "             for i in range(num_timesteps)]\n",
    "    \n",
    "    dxtp1_dxt = [M.T for _ in range(num_timesteps-1)]\n",
    "\n",
    "    adjoints = compute_adjoints(DJ_Dx, dxtp1_dxt)[:num_timesteps]\n",
    "\n",
    "    ### Compute numerical gradient using finite differences\n",
    "    for t in range(num_timesteps): # For each timestep\n",
    "        adjoint_approx = np.zeros((vec_length, 1))\n",
    "\n",
    "        for i in range(vec_length): # For each element in x(t)\n",
    "            #Perturb state x(t) in each dimension\n",
    "            state_t       = simulated_state_over_time[t]\n",
    "            state_t_plus  = state_t.copy()\n",
    "            state_t_minus = state_t.copy()\n",
    "\n",
    "            state_t_plus[i] += epsilon \n",
    "            state_t_minus[i] -= epsilon\n",
    "\n",
    "\n",
    "            #Simulate starting from time t through tau=num_timesteps\n",
    "            _, plus_state_t_tau = helper.compute_affine_time_evolution_simple(state_t_plus,   M, F*f_guess, num_timesteps-t)\n",
    "            _, minus_state_t_tau = helper.compute_affine_time_evolution_simple(state_t_minus, M, F*f_guess, num_timesteps-t)\n",
    "\n",
    "            observed_state_t_tau = observed_state_over_time[t:num_timesteps]\n",
    "\n",
    "            # Compute how perturbation affects J\n",
    "            J_plus =  compute_J(observed_state_t_tau,  plus_state_t_tau)\n",
    "            J_minus = compute_J(observed_state_t_tau, minus_state_t_tau)\n",
    "\n",
    "            # Compute finite difference approximation\n",
    "            adjoint_approx[i] = (J_plus - J_minus) / (2*epsilon)\n",
    "\n",
    "        #Compute percent error between analytic (adjoint) and numerical (finite-difference)\n",
    "        adjoint = adjoints[t]\n",
    "\n",
    "        percent_error = 100 * np.linalg.norm(adjoint - adjoint_approx) / np.linalg.norm(adjoint)\n",
    "        percent_errors.append(percent_error)\n",
    "\n",
    "    return percent_errors\n",
    "\n",
    "\n",
    "num_timesteps = 4\n",
    "# Call the function with all necessary arguments\n",
    "percent_errors = test_adjoint(observed_state_over_time, x0, M, F, f_guess, num_timesteps, nr, nc)\n",
    "\n",
    "# Print results\n",
    "for t, percent_error in enumerate(percent_errors):\n",
    "    print(f\"Percent error at timestep {t}: {percent_error:.8f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to evaluate the functionality of ```compute_dJ_df```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent error: 0.00000069\n"
     ]
    }
   ],
   "source": [
    "def dJ_df_check(observed_state_over_time, x0, M, F, f_guess, num_timesteps, \n",
    "               epsilon = 1e-6):\n",
    "    \"\"\"\n",
    "    This function tests compute_dJ_df by comparing it to a numerical approximation of the gradient.\n",
    "    \"\"\"\n",
    "\n",
    "    vec_length = len(observed_state_over_time[0])\n",
    "\n",
    "    observed_state_over_time     = observed_state_over_time[:num_timesteps]\n",
    "    _, simulated_state_over_time = helper.compute_affine_time_evolution_simple(x0, M, F*f_guess, num_timesteps)\n",
    "\n",
    "    ### Compute analytical gradient using adjoint method + chain rule\n",
    "    dJ_df = compute_dJ_df(M, F, observed_state_over_time, simulated_state_over_time)\n",
    "\n",
    "    ### Compute numerical gradient using finite differences\n",
    "    dJ_df_approx = np.zeros((vec_length,1))\n",
    "    for i in range(vec_length):\n",
    "        f_plus  = f_guess.copy()\n",
    "        f_minus = f_guess.copy()\n",
    "\n",
    "        f_plus[i]  += epsilon\n",
    "        f_minus[i] -= epsilon\n",
    "\n",
    "        # Simulate future states\n",
    "        _, plus_state_over_time  = helper.compute_affine_time_evolution_simple(x0, M, F*f_plus, num_timesteps)\n",
    "        _, minus_state_over_time = helper.compute_affine_time_evolution_simple(x0, M, F*f_minus, num_timesteps)\n",
    "\n",
    "        \n",
    "\n",
    "        # Compute the loss for the modified state\n",
    "        J_plus  = compute_J(observed_state_over_time, plus_state_over_time)\n",
    "        J_minus = compute_J(observed_state_over_time, minus_state_over_time)\n",
    "\n",
    "        # Compute the partial derivative\n",
    "        dJ_df_approx[i] = (J_plus - J_minus) / (2*epsilon)\n",
    "\n",
    "    percent_error = 100 * np.linalg.norm(dJ_df - dJ_df_approx) / np.linalg.norm(dJ_df)\n",
    "\n",
    "    return percent_error\n",
    "\n",
    "num_timesteps = 4\n",
    "# Call the function with all necessary arguments\n",
    "percent_error = dJ_df_check(observed_state_over_time, x0, M, F, f_guess, num_timesteps)\n",
    "\n",
    "print(f\"Percent error: {percent_error:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of adjoints: 10\n",
      "Shape of each adjoint: (1024, 1)\n",
      "(1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "num_timesteps = 10  # Adjust this to match your actual number of timesteps\n",
    "DJ_Dx = [compute_DJ_Dxt(observed_state_over_time[i], guess_state_over_time[i])\n",
    "         for i in range(num_timesteps)]\n",
    "dxtp1_dxt = [M.T for _ in range(num_timesteps-1)]\n",
    "adjoints = compute_adjoints(DJ_Dx, dxtp1_dxt)\n",
    "\n",
    "# Check the size of the adjoint\n",
    "print(f\"Number of adjoints: {len(adjoints)}\")\n",
    "print(f\"Shape of each adjoint: {adjoints[0].shape}\")\n",
    "\n",
    "print(M.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
